{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5f310246",
      "metadata": {
        "id": "5f310246"
      },
      "source": [
        "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
        "<table align=\"center\">\n",
        " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Regression_tuner.ipynb\">\n",
        "        <img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Regression_tuner.ipynb\">\n",
        "        <img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />View Source on GitHub</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2360c95e",
      "metadata": {
        "id": "2360c95e"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "tf.keras.utils.set_random_seed(0)\n",
        "from tensorflow.keras.utils import plot_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b45e3013",
      "metadata": {
        "id": "b45e3013"
      },
      "source": [
        "# Abalone Dataset\n",
        "\n",
        "Abalones are marine snails that can be found along coasts of almost every continent.\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0b/AbaloneInside.jpg/440px-AbaloneInside.jpg\" alt=\"abalone\" border=\"0\" width=\"400\" height=\"500\">\n",
        "\n",
        "\n",
        "\n",
        "In this notebook we are going to Predict the age of abalone from physical measurements. [Link to documentation](https://archive.ics.uci.edu/ml/datasets/abalone)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "801c6c84",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "801c6c84",
        "outputId": "be15df68-618a-408b-9960-11b3286d9ee5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
              "0   0.435     0.335   0.110         0.334          0.1355          0.0775   \n",
              "1   0.585     0.450   0.125         0.874          0.3545          0.2075   \n",
              "2   0.655     0.510   0.160         1.092          0.3960          0.2825   \n",
              "3   0.545     0.425   0.125         0.768          0.2940          0.1495   \n",
              "4   0.545     0.420   0.130         0.879          0.3740          0.1695   \n",
              "\n",
              "   Shell weight  Age  \n",
              "0        0.0965    7  \n",
              "1        0.2250    6  \n",
              "2        0.3700   14  \n",
              "3        0.2600   16  \n",
              "4        0.2300   13  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30e3d8cf-f6dd-4105-a733-8dbe9ed0ea2b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Diameter</th>\n",
              "      <th>Height</th>\n",
              "      <th>Whole weight</th>\n",
              "      <th>Shucked weight</th>\n",
              "      <th>Viscera weight</th>\n",
              "      <th>Shell weight</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.435</td>\n",
              "      <td>0.335</td>\n",
              "      <td>0.110</td>\n",
              "      <td>0.334</td>\n",
              "      <td>0.1355</td>\n",
              "      <td>0.0775</td>\n",
              "      <td>0.0965</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.585</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.3545</td>\n",
              "      <td>0.2075</td>\n",
              "      <td>0.2250</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.655</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.160</td>\n",
              "      <td>1.092</td>\n",
              "      <td>0.3960</td>\n",
              "      <td>0.2825</td>\n",
              "      <td>0.3700</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.545</td>\n",
              "      <td>0.425</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.768</td>\n",
              "      <td>0.2940</td>\n",
              "      <td>0.1495</td>\n",
              "      <td>0.2600</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.545</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.130</td>\n",
              "      <td>0.879</td>\n",
              "      <td>0.3740</td>\n",
              "      <td>0.1695</td>\n",
              "      <td>0.2300</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30e3d8cf-f6dd-4105-a733-8dbe9ed0ea2b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-30e3d8cf-f6dd-4105-a733-8dbe9ed0ea2b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-30e3d8cf-f6dd-4105-a733-8dbe9ed0ea2b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e33c918e-0557-44d0-b4c0-a84b4f3f50a0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e33c918e-0557-44d0-b4c0-a84b4f3f50a0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e33c918e-0557-44d0-b4c0-a84b4f3f50a0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 3320,\n  \"fields\": [\n    {\n      \"column\": \"Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12116373129783752,\n        \"min\": 0.075,\n        \"max\": 0.815,\n        \"num_unique_values\": 132,\n        \"samples\": [\n          0.64,\n          0.26,\n          0.575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Diameter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1001199358725016,\n        \"min\": 0.055,\n        \"max\": 0.65,\n        \"num_unique_values\": 110,\n        \"samples\": [\n          0.23,\n          0.3,\n          0.42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.042708242545774135,\n        \"min\": 0.0,\n        \"max\": 1.13,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          0.22,\n          0.04,\n          0.015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Whole weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49118197923811296,\n        \"min\": 0.002,\n        \"max\": 2.8255,\n        \"num_unique_values\": 2145,\n        \"samples\": [\n          1.145,\n          0.499,\n          0.9415\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Shucked weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22222323442145436,\n        \"min\": 0.001,\n        \"max\": 1.488,\n        \"num_unique_values\": 1409,\n        \"samples\": [\n          0.13,\n          0.4,\n          0.214\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Viscera weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1101817715893136,\n        \"min\": 0.0005,\n        \"max\": 0.76,\n        \"num_unique_values\": 845,\n        \"samples\": [\n          0.097,\n          0.071,\n          0.541\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Shell weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14026098949905869,\n        \"min\": 0.0015,\n        \"max\": 1.005,\n        \"num_unique_values\": 855,\n        \"samples\": [\n          0.3045,\n          0.1255,\n          0.2035\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 27,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          12,\n          4,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df_train = pd.read_csv(\n",
        "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
        "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
        "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9edcad0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "9edcad0b",
        "outputId": "a8c8a3b3-1170-46a9-84a1-faeaec27b665"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Length     Diameter       Height  Whole weight  Shucked weight  \\\n",
              "count  3320.000000  3320.000000  3320.000000   3320.000000     3320.000000   \n",
              "mean      0.522693     0.406575     0.139271      0.824734        0.357705   \n",
              "std       0.121164     0.100120     0.042708      0.491182        0.222223   \n",
              "min       0.075000     0.055000     0.000000      0.002000        0.001000   \n",
              "25%       0.450000     0.345000     0.115000      0.436375        0.181500   \n",
              "50%       0.540000     0.425000     0.140000      0.795250        0.335500   \n",
              "75%       0.615000     0.480000     0.165000      1.150000        0.504500   \n",
              "max       0.815000     0.650000     1.130000      2.825500        1.488000   \n",
              "\n",
              "       Viscera weight  Shell weight          Age  \n",
              "count     3320.000000   3320.000000  3320.000000  \n",
              "mean         0.180162      0.237921     9.896988  \n",
              "std          0.110182      0.140261     3.205654  \n",
              "min          0.000500      0.001500     1.000000  \n",
              "25%          0.092000      0.127375     8.000000  \n",
              "50%          0.170750      0.230000     9.000000  \n",
              "75%          0.253125      0.325000    11.000000  \n",
              "max          0.760000      1.005000    27.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-046681d2-fa27-4db4-8560-4e1b95ef7bfb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Diameter</th>\n",
              "      <th>Height</th>\n",
              "      <th>Whole weight</th>\n",
              "      <th>Shucked weight</th>\n",
              "      <th>Viscera weight</th>\n",
              "      <th>Shell weight</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3320.000000</td>\n",
              "      <td>3320.000000</td>\n",
              "      <td>3320.000000</td>\n",
              "      <td>3320.000000</td>\n",
              "      <td>3320.000000</td>\n",
              "      <td>3320.000000</td>\n",
              "      <td>3320.000000</td>\n",
              "      <td>3320.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.522693</td>\n",
              "      <td>0.406575</td>\n",
              "      <td>0.139271</td>\n",
              "      <td>0.824734</td>\n",
              "      <td>0.357705</td>\n",
              "      <td>0.180162</td>\n",
              "      <td>0.237921</td>\n",
              "      <td>9.896988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.121164</td>\n",
              "      <td>0.100120</td>\n",
              "      <td>0.042708</td>\n",
              "      <td>0.491182</td>\n",
              "      <td>0.222223</td>\n",
              "      <td>0.110182</td>\n",
              "      <td>0.140261</td>\n",
              "      <td>3.205654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.075000</td>\n",
              "      <td>0.055000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.345000</td>\n",
              "      <td>0.115000</td>\n",
              "      <td>0.436375</td>\n",
              "      <td>0.181500</td>\n",
              "      <td>0.092000</td>\n",
              "      <td>0.127375</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.795250</td>\n",
              "      <td>0.335500</td>\n",
              "      <td>0.170750</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.165000</td>\n",
              "      <td>1.150000</td>\n",
              "      <td>0.504500</td>\n",
              "      <td>0.253125</td>\n",
              "      <td>0.325000</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.815000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>1.130000</td>\n",
              "      <td>2.825500</td>\n",
              "      <td>1.488000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>1.005000</td>\n",
              "      <td>27.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-046681d2-fa27-4db4-8560-4e1b95ef7bfb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-046681d2-fa27-4db4-8560-4e1b95ef7bfb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-046681d2-fa27-4db4-8560-4e1b95ef7bfb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-45140e7e-e353-4f7c-8f91-a7ce1bcbaa66\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-45140e7e-e353-4f7c-8f91-a7ce1bcbaa66')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-45140e7e-e353-4f7c-8f91-a7ce1bcbaa66 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1173.6387462937578,\n        \"min\": 0.075,\n        \"max\": 3320.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.5226927710843373,\n          0.54,\n          3320.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Diameter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1173.6729385238689,\n        \"min\": 0.055,\n        \"max\": 3320.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.4065753012048193,\n          0.425,\n          3320.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1173.7098351783097,\n        \"min\": 0.0,\n        \"max\": 3320.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.1392710843373494,\n          0.14,\n          3320.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Whole weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1173.4679948041755,\n        \"min\": 0.002,\n        \"max\": 3320.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.8247344879518074,\n          0.79525,\n          3320.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Shucked weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1173.641253444102,\n        \"min\": 0.001,\n        \"max\": 3320.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.35770466867469874,\n          0.3355,\n          3320.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Viscera weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1173.7181482484305,\n        \"min\": 0.0005,\n        \"max\": 3320.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.1801617469879518,\n          0.17075,\n          3320.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Shell weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1173.6928942426212,\n        \"min\": 0.0015,\n        \"max\": 3320.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.2379206325301205,\n          0.23,\n          3320.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1170.332805946877,\n        \"min\": 1.0,\n        \"max\": 3320.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          9.89698795180723,\n          9.0,\n          3320.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3c554e97",
      "metadata": {
        "id": "3c554e97"
      },
      "outputs": [],
      "source": [
        "y_train = df_train.pop('Age')\n",
        "X_train = df_train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fede61bd",
      "metadata": {
        "id": "fede61bd"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv(\n",
        "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_test.csv\",\n",
        "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
        "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
        "y_test = df_test.pop('Age')\n",
        "X_test = df_test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "de841977",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de841977",
        "outputId": "baa7a050-587a-48c7-efa8-c832805101f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (3320, 7), X_test shape: (850, 7)\n"
          ]
        }
      ],
      "source": [
        "print(f'X_train shape: {X_train.shape}, X_test shape: {X_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_feauture = X_train.shape[1]\n",
        "num_feauture"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBkro7192YrA",
        "outputId": "e1b0153b-cb93-4abd-9e41-a70873d3acb5"
      },
      "id": "mBkro7192YrA",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a1bf8de",
      "metadata": {
        "id": "4a1bf8de"
      },
      "source": [
        "## Regression Losses\n",
        "\n",
        "- **Mean Squared Error (MSE)**:\n",
        "\n",
        "```python\n",
        "tf.keras.losses.MSE\n",
        "```\n",
        "```python\n",
        "model.compile(loss='mse') or model.compile(loss=tf.keras.losses.MSE)\n",
        "```\n",
        "\n",
        "$$ \\mathrm{MSE} = \\frac{\\sum_{i=1}^n\\left( y_i - \\hat{y_i}\\right)^2}{n}$$\n",
        "\n",
        "\n",
        "- **Mean Absolute Error (MAE)**:\n",
        "\n",
        "```python\n",
        "tf.keras.losses.MAE\n",
        "```\n",
        "```python\n",
        "model.compile(loss='mae') or model.compile(loss=tf.keras.losses.MAE)\n",
        "```\n",
        "\n",
        "$$ \\mathrm{MAE} = \\frac{\\sum_{i=1}^n\\left| y_i - \\hat{y_i}\\right|}{n}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "313693e1",
      "metadata": {
        "id": "313693e1"
      },
      "source": [
        "## Question 1: Create a net with at least 1 hidden layer\n",
        "\n",
        "\n",
        "1. You can use the [Functional API](https://keras.io/guides/functional_api/):\n",
        "\n",
        "You need to start with an input data entry:\n",
        "```python    \n",
        "    inputs = keras.Input(shape=(...,))\n",
        "    layer_1 = layers.Dense(...)(inputs)\n",
        "```\n",
        "\n",
        "and the network outputs:\n",
        "```python\n",
        "outputs = layers.Dense(...)(previous_layer)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "```\n",
        "\n",
        "2. Or you can use [Sequential API](https://keras.io/guides/sequential_model/)\n",
        "\n",
        "```python\n",
        "model = keras.Sequential(name='example_model')\n",
        "model.add(layers.Dense(..., input_shape=(8,))\n",
        "model.add(...\n",
        "```\n",
        "\n",
        "You can introduce regularization methods seen in [Prevent_Overfitting.ipynb](https://github.com/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Prevent_Overfitting.ipynb) like [Dropout layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout):\n",
        "\n",
        "\n",
        "```python\n",
        "tf.keras.layers.Dropout(\n",
        "    rate, noise_shape=None, seed=None, **kwargs\n",
        ")\n",
        "```\n",
        "\n",
        "With Functional API:\n",
        "```python\n",
        "next_layer = layers.Dropout(0.4)(prev_layer)\n",
        "```\n",
        "With Sequential:\n",
        "```python\n",
        "model.add(layers.Dropout(0.4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0f142132",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "0f142132",
        "outputId": "e9b930f4-b5c1-488a-83a3-8670261abcc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Could not interpret activation function identifier: Ellipsis",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-9-3547785554.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, lora_rank, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/activations/__init__.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;34mf\"Could not interpret activation function identifier: {identifier}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Could not interpret activation function identifier: Ellipsis"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.Dense(..., input_shape=(...,), activation=...))\n",
        "...\n",
        "# output layer\n",
        "model.add(layers.Dense(..., activation=...))\n",
        "\n",
        "## model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2b73b78f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "2b73b78f",
        "outputId": "ce92e4c4-c803-49f5-cc2c-5c30082393b6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid dtype: ellipsis",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-10-2096949452.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Using the Functional API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 1. Define the input layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 2. Build the hidden layers, You can also add dropout or other layer types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_size, dtype, sparse, batch_shape, name, tensor, optional)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \"\"\"\n\u001b[0;32m--> 191\u001b[0;31m     layer = InputLayer(\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shape, batch_size, dtype, sparse, batch_shape, input_tensor, optional, name, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36mstandardize_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;31m# JAX2TF tracing uses JAX-native dimension expressions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_int_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             raise ValueError(\n\u001b[1;32m    583\u001b[0m                 \u001b[0;34mf\"Cannot convert '{shape}' to a shape. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36mis_int_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keras.backend.is_int_dtype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_int_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"uint\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36mstandardize_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALLOWED_DTYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid dtype: {dtype}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid dtype: ellipsis"
          ]
        }
      ],
      "source": [
        "# Using the Functional API\n",
        "# 1. Define the input layer\n",
        "inputs = keras.Input(shape=(...,))\n",
        "\n",
        "# 2. Build the hidden layers, You can also add dropout or other layer types\n",
        "x = layers.Dense(..., activation=...)(inputs)\n",
        "...\n",
        "x = layers.Dropout(...)(x)\n",
        "x = layers.Dense(..., activation=...)(x)\n",
        "\n",
        "# 3. Define the output layer\n",
        "outputs = layers.Dense(..., activation=...)(x)\n",
        "\n",
        "# 4. Create the model by specifying inputs and outputs\n",
        "model = keras.Model(inputs=..., outputs=..., name='functional_model')\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(num_feauture, ), name='input_layer')\n",
        "l_1 = layers.Dense(128, activation='linear', name='layer_1')(inputs)\n",
        "outputs = layers.Dense(1, activation=\"linear\", name='output_layer')(l_1)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='example_model')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "_qLpLpXz3gXX",
        "outputId": "01b88a7b-8fda-4638-da01-d9a73c2340c2"
      },
      "id": "_qLpLpXz3gXX",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"example_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"example_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,153\u001b[0m (4.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,153</span> (4.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,153\u001b[0m (4.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,153</span> (4.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b42f777",
      "metadata": {
        "id": "2b42f777"
      },
      "source": [
        "[Early stopping callback](https://keras.io/api/callbacks/early_stopping/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3ceb6dc8",
      "metadata": {
        "id": "3ceb6dc8"
      },
      "outputs": [],
      "source": [
        "# Early stopping callback\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=15,\n",
        "    min_delta = 0,\n",
        "    restore_best_weights=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "26bb1a7b",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26bb1a7b",
        "outputId": "78f556f3-3986-4e6f-c66b-cd964ef75c7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 80.2935 - mae: 8.3956 - val_loss: 19.0020 - val_mae: 3.4737\n",
            "Epoch 2/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11.9086 - mae: 2.5829 - val_loss: 8.9803 - val_mae: 2.2313\n",
            "Epoch 3/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2647 - mae: 2.1109 - val_loss: 8.3744 - val_mae: 2.1245\n",
            "Epoch 4/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6741 - mae: 2.0071 - val_loss: 7.8295 - val_mae: 2.0414\n",
            "Epoch 5/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1640 - mae: 1.9244 - val_loss: 7.3860 - val_mae: 1.9867\n",
            "Epoch 6/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7558 - mae: 1.8652 - val_loss: 7.0538 - val_mae: 1.9531\n",
            "Epoch 7/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4544 - mae: 1.8275 - val_loss: 6.8205 - val_mae: 1.9312\n",
            "Epoch 8/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2444 - mae: 1.8063 - val_loss: 6.6594 - val_mae: 1.9188\n",
            "Epoch 9/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0991 - mae: 1.7920 - val_loss: 6.5417 - val_mae: 1.9115\n",
            "Epoch 10/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9916 - mae: 1.7806 - val_loss: 6.4456 - val_mae: 1.9036\n",
            "Epoch 11/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9027 - mae: 1.7704 - val_loss: 6.3583 - val_mae: 1.8950\n",
            "Epoch 12/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8215 - mae: 1.7597 - val_loss: 6.2741 - val_mae: 1.8853\n",
            "Epoch 13/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7430 - mae: 1.7484 - val_loss: 6.1905 - val_mae: 1.8751\n",
            "Epoch 14/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6650 - mae: 1.7363 - val_loss: 6.1070 - val_mae: 1.8637\n",
            "Epoch 15/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5869 - mae: 1.7238 - val_loss: 6.0234 - val_mae: 1.8512\n",
            "Epoch 16/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5085 - mae: 1.7111 - val_loss: 5.9401 - val_mae: 1.8379\n",
            "Epoch 17/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4300 - mae: 1.6979 - val_loss: 5.8574 - val_mae: 1.8240\n",
            "Epoch 18/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3517 - mae: 1.6847 - val_loss: 5.7760 - val_mae: 1.8100\n",
            "Epoch 19/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.2741 - mae: 1.6718 - val_loss: 5.6963 - val_mae: 1.7952\n",
            "Epoch 20/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1977 - mae: 1.6593 - val_loss: 5.6191 - val_mae: 1.7802\n",
            "Epoch 21/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.1234 - mae: 1.6471 - val_loss: 5.5451 - val_mae: 1.7651\n",
            "Epoch 22/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0517 - mae: 1.6351 - val_loss: 5.4752 - val_mae: 1.7502\n",
            "Epoch 23/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9835 - mae: 1.6237 - val_loss: 5.4100 - val_mae: 1.7360\n",
            "Epoch 24/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9196 - mae: 1.6128 - val_loss: 5.3504 - val_mae: 1.7222\n",
            "Epoch 25/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8607 - mae: 1.6024 - val_loss: 5.2967 - val_mae: 1.7091\n",
            "Epoch 26/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8072 - mae: 1.5932 - val_loss: 5.2492 - val_mae: 1.6963\n",
            "Epoch 27/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7595 - mae: 1.5852 - val_loss: 5.2081 - val_mae: 1.6849\n",
            "Epoch 28/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7178 - mae: 1.5786 - val_loss: 5.1731 - val_mae: 1.6748\n",
            "Epoch 29/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6819 - mae: 1.5735 - val_loss: 5.1438 - val_mae: 1.6662\n",
            "Epoch 30/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6515 - mae: 1.5697 - val_loss: 5.1197 - val_mae: 1.6589\n",
            "Epoch 31/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6262 - mae: 1.5665 - val_loss: 5.1002 - val_mae: 1.6526\n",
            "Epoch 32/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6055 - mae: 1.5643 - val_loss: 5.0847 - val_mae: 1.6475\n",
            "Epoch 33/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5887 - mae: 1.5626 - val_loss: 5.0724 - val_mae: 1.6435\n",
            "Epoch 34/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5753 - mae: 1.5612 - val_loss: 5.0629 - val_mae: 1.6403\n",
            "Epoch 35/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5646 - mae: 1.5601 - val_loss: 5.0556 - val_mae: 1.6376\n",
            "Epoch 36/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.5563 - mae: 1.5594 - val_loss: 5.0500 - val_mae: 1.6355\n",
            "Epoch 37/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5497 - mae: 1.5589 - val_loss: 5.0458 - val_mae: 1.6337\n",
            "Epoch 38/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5446 - mae: 1.5585 - val_loss: 5.0425 - val_mae: 1.6322\n",
            "Epoch 39/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5406 - mae: 1.5582 - val_loss: 5.0400 - val_mae: 1.6311\n",
            "Epoch 40/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5375 - mae: 1.5580 - val_loss: 5.0380 - val_mae: 1.6303\n",
            "Epoch 41/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5350 - mae: 1.5578 - val_loss: 5.0364 - val_mae: 1.6296\n",
            "Epoch 42/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5329 - mae: 1.5577 - val_loss: 5.0350 - val_mae: 1.6291\n",
            "Epoch 43/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5313 - mae: 1.5576 - val_loss: 5.0338 - val_mae: 1.6286\n",
            "Epoch 44/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5299 - mae: 1.5576 - val_loss: 5.0328 - val_mae: 1.6283\n",
            "Epoch 45/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5287 - mae: 1.5576 - val_loss: 5.0318 - val_mae: 1.6280\n",
            "Epoch 46/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5276 - mae: 1.5576 - val_loss: 5.0308 - val_mae: 1.6278\n",
            "Epoch 47/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5267 - mae: 1.5577 - val_loss: 5.0298 - val_mae: 1.6276\n",
            "Epoch 48/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5258 - mae: 1.5577 - val_loss: 5.0289 - val_mae: 1.6275\n",
            "Epoch 49/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5249 - mae: 1.5578 - val_loss: 5.0280 - val_mae: 1.6273\n",
            "Epoch 50/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5242 - mae: 1.5578 - val_loss: 5.0270 - val_mae: 1.6273\n",
            "Epoch 51/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5234 - mae: 1.5578 - val_loss: 5.0260 - val_mae: 1.6272\n",
            "Epoch 52/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5227 - mae: 1.5578 - val_loss: 5.0251 - val_mae: 1.6272\n",
            "Epoch 53/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.5220 - mae: 1.5578 - val_loss: 5.0241 - val_mae: 1.6271\n",
            "Epoch 54/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.5213 - mae: 1.5578 - val_loss: 5.0231 - val_mae: 1.6270\n",
            "Epoch 55/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5206 - mae: 1.5578 - val_loss: 5.0221 - val_mae: 1.6270\n",
            "Epoch 56/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.5199 - mae: 1.5578 - val_loss: 5.0211 - val_mae: 1.6270\n",
            "Epoch 57/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5193 - mae: 1.5578 - val_loss: 5.0201 - val_mae: 1.6269\n",
            "Epoch 58/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5186 - mae: 1.5578 - val_loss: 5.0192 - val_mae: 1.6269\n",
            "Epoch 59/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5180 - mae: 1.5577 - val_loss: 5.0182 - val_mae: 1.6268\n",
            "Epoch 60/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5174 - mae: 1.5577 - val_loss: 5.0172 - val_mae: 1.6268\n",
            "Epoch 61/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5168 - mae: 1.5577 - val_loss: 5.0162 - val_mae: 1.6267\n",
            "Epoch 62/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5162 - mae: 1.5576 - val_loss: 5.0152 - val_mae: 1.6267\n",
            "Epoch 63/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5156 - mae: 1.5576 - val_loss: 5.0143 - val_mae: 1.6266\n",
            "Epoch 64/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5150 - mae: 1.5575 - val_loss: 5.0133 - val_mae: 1.6266\n",
            "Epoch 65/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5144 - mae: 1.5575 - val_loss: 5.0123 - val_mae: 1.6265\n",
            "Epoch 66/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5138 - mae: 1.5575 - val_loss: 5.0114 - val_mae: 1.6265\n",
            "Epoch 67/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5133 - mae: 1.5574 - val_loss: 5.0105 - val_mae: 1.6264\n",
            "Epoch 68/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5127 - mae: 1.5574 - val_loss: 5.0095 - val_mae: 1.6263\n",
            "Epoch 69/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5122 - mae: 1.5573 - val_loss: 5.0086 - val_mae: 1.6263\n",
            "Epoch 70/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5116 - mae: 1.5573 - val_loss: 5.0077 - val_mae: 1.6262\n",
            "Epoch 71/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5111 - mae: 1.5572 - val_loss: 5.0068 - val_mae: 1.6262\n",
            "Epoch 72/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5106 - mae: 1.5572 - val_loss: 5.0059 - val_mae: 1.6261\n",
            "Epoch 73/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5101 - mae: 1.5572 - val_loss: 5.0050 - val_mae: 1.6260\n",
            "Epoch 74/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5096 - mae: 1.5571 - val_loss: 5.0042 - val_mae: 1.6260\n",
            "Epoch 75/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5091 - mae: 1.5571 - val_loss: 5.0033 - val_mae: 1.6259\n",
            "Epoch 76/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5086 - mae: 1.5570 - val_loss: 5.0024 - val_mae: 1.6259\n",
            "Epoch 77/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5082 - mae: 1.5570 - val_loss: 5.0016 - val_mae: 1.6258\n",
            "Epoch 78/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5077 - mae: 1.5570 - val_loss: 5.0008 - val_mae: 1.6257\n",
            "Epoch 79/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5072 - mae: 1.5569 - val_loss: 4.9999 - val_mae: 1.6257\n",
            "Epoch 80/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5068 - mae: 1.5569 - val_loss: 4.9991 - val_mae: 1.6256\n",
            "Epoch 81/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5063 - mae: 1.5568 - val_loss: 4.9983 - val_mae: 1.6255\n",
            "Epoch 82/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5059 - mae: 1.5568 - val_loss: 4.9975 - val_mae: 1.6255\n",
            "Epoch 83/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5055 - mae: 1.5567 - val_loss: 4.9967 - val_mae: 1.6254\n",
            "Epoch 84/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5051 - mae: 1.5567 - val_loss: 4.9960 - val_mae: 1.6253\n",
            "Epoch 85/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5047 - mae: 1.5567 - val_loss: 4.9952 - val_mae: 1.6252\n",
            "Epoch 86/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5043 - mae: 1.5566 - val_loss: 4.9944 - val_mae: 1.6252\n",
            "Epoch 87/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5039 - mae: 1.5566 - val_loss: 4.9937 - val_mae: 1.6251\n",
            "Epoch 88/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5035 - mae: 1.5565 - val_loss: 4.9929 - val_mae: 1.6250\n",
            "Epoch 89/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5031 - mae: 1.5565 - val_loss: 4.9922 - val_mae: 1.6250\n",
            "Epoch 90/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5027 - mae: 1.5565 - val_loss: 4.9915 - val_mae: 1.6249\n",
            "Epoch 91/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5024 - mae: 1.5564 - val_loss: 4.9908 - val_mae: 1.6248\n",
            "Epoch 92/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.5020 - mae: 1.5564 - val_loss: 4.9901 - val_mae: 1.6247\n",
            "Epoch 93/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.5017 - mae: 1.5563 - val_loss: 4.9894 - val_mae: 1.6247\n",
            "Epoch 94/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5013 - mae: 1.5563 - val_loss: 4.9887 - val_mae: 1.6246\n",
            "Epoch 95/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5010 - mae: 1.5563 - val_loss: 4.9880 - val_mae: 1.6245\n",
            "Epoch 96/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5007 - mae: 1.5562 - val_loss: 4.9873 - val_mae: 1.6245\n",
            "Epoch 97/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5004 - mae: 1.5562 - val_loss: 4.9866 - val_mae: 1.6244\n",
            "Epoch 98/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5001 - mae: 1.5562 - val_loss: 4.9860 - val_mae: 1.6243\n",
            "Epoch 99/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4997 - mae: 1.5562 - val_loss: 4.9853 - val_mae: 1.6243\n",
            "Epoch 100/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.4994 - mae: 1.5561 - val_loss: 4.9847 - val_mae: 1.6242\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',\n",
        "    metrics=['mae'],\n",
        ")\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=100,\n",
        "    validation_split=0.2,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping],  # early stopping\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Loss: {}'.format(results[0]))\n",
        "print('Test Accuracy: {}'.format(results[1]))\n",
        "plot_decision_boundary(lambda x: (\n",
        "    model.predict(x) > 0.5).astype(\"int32\"), X_test, y_test)"
      ],
      "metadata": {
        "id": "E34Nmcjy4jmZ"
      },
      "id": "E34Nmcjy4jmZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cdfd5bb",
      "metadata": {
        "id": "0cdfd5bb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def show_loss_evolution(history):\n",
        "\n",
        "    hist = pd.DataFrame(history.history)\n",
        "    hist['epoch'] = history.epoch\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('MSE')\n",
        "    plt.plot(hist['epoch'], hist['loss'], label='Train Error')\n",
        "    plt.plot(hist['epoch'], hist['val_loss'], label='Val Error')\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "show_loss_evolution(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "644f80fd",
      "metadata": {
        "id": "644f80fd"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c909754",
      "metadata": {
        "id": "5c909754"
      },
      "source": [
        "## Question 2: Normalize the inputs and train the same model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d9ed6000",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9ed6000",
        "outputId": "6e7f273c-f3da-472e-d8dd-b9f7a1c84cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train mu, sigma [ 2.77689518e-16  4.65491099e-17  2.50402109e-16 -2.81434849e-16\n",
            "  2.18299274e-16  1.77100637e-16 -1.05404306e-16] [1. 1. 1. 1. 1. 1. 1.]\n",
            "X_test mu, sigma [0.05808422 0.06917445 0.03098307 0.04461505 0.04160742 0.02421514\n",
            " 0.03516632] [0.95187926 0.95135017 0.89294094 0.99223632 0.99454932 0.97495047\n",
            " 0.96304109]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Ajustar el scaler solo con X_train y transformar ambos sets\n",
        "X_train_norm = scaler.fit_transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "print('X_train mu, sigma', X_train_norm.mean(0), X_train_norm.std(0))\n",
        "print('X_test mu, sigma', X_test_norm.mean(0), X_test_norm.std(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "16ac44c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "16ac44c0",
        "outputId": "8a4a495f-bba4-4b10-c689-2c742823b0da"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"example_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"example_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,153\u001b[0m (4.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,153</span> (4.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,153\u001b[0m (4.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,153</span> (4.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(num_feauture, ), name='input_layer')\n",
        "l_1 = layers.Dense(128, activation='linear', name='layer_1')(inputs)\n",
        "outputs = layers.Dense(1, activation=\"linear\", name='output_layer')(l_1)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='example_model')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3b1d2308",
      "metadata": {
        "id": "3b1d2308"
      },
      "outputs": [],
      "source": [
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',        # observamos la pérdida en validación (MSE, MAE, etc.)\n",
        "    patience=5,                # si no mejora en 5 épocas, se detiene\n",
        "    min_delta=0.001,           # mejora mínima para resetear el contador de paciencia\n",
        "    restore_best_weights=True # restaurar los mejores pesos al final\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "173bef88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "173bef88",
        "outputId": "190af21a-81bb-41e2-98e9-ac95992e3dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 95.8586 - mae: 9.4616 - val_loss: 72.2700 - val_mae: 8.1083\n",
            "Epoch 2/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 56.8043 - mae: 7.1117 - val_loss: 22.8783 - val_mae: 4.1635\n",
            "Epoch 3/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14.5133 - mae: 3.0834 - val_loss: 5.7540 - val_mae: 1.6231\n",
            "Epoch 4/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7236 - mae: 1.5157 - val_loss: 5.1069 - val_mae: 1.6341\n",
            "Epoch 5/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5798 - mae: 1.5834 - val_loss: 5.1150 - val_mae: 1.6393\n",
            "Epoch 6/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5831 - mae: 1.5897 - val_loss: 5.1179 - val_mae: 1.6389\n",
            "Epoch 7/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5801 - mae: 1.5904 - val_loss: 5.1141 - val_mae: 1.6385\n",
            "Epoch 8/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5757 - mae: 1.5905 - val_loss: 5.1065 - val_mae: 1.6379\n",
            "Epoch 9/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5706 - mae: 1.5902 - val_loss: 5.0974 - val_mae: 1.6371\n",
            "Epoch 10/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.5653 - mae: 1.5896 - val_loss: 5.0880 - val_mae: 1.6363\n",
            "Epoch 11/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.5604 - mae: 1.5889 - val_loss: 5.0788 - val_mae: 1.6357\n",
            "Epoch 12/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.5559 - mae: 1.5884 - val_loss: 5.0701 - val_mae: 1.6350\n",
            "Epoch 13/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5520 - mae: 1.5879 - val_loss: 5.0619 - val_mae: 1.6344\n",
            "Epoch 14/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5486 - mae: 1.5875 - val_loss: 5.0544 - val_mae: 1.6338\n",
            "Epoch 15/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5457 - mae: 1.5870 - val_loss: 5.0474 - val_mae: 1.6332\n",
            "Epoch 16/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5433 - mae: 1.5866 - val_loss: 5.0410 - val_mae: 1.6326\n",
            "Epoch 17/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5412 - mae: 1.5862 - val_loss: 5.0351 - val_mae: 1.6320\n",
            "Epoch 18/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5396 - mae: 1.5858 - val_loss: 5.0297 - val_mae: 1.6314\n",
            "Epoch 19/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5384 - mae: 1.5854 - val_loss: 5.0247 - val_mae: 1.6309\n",
            "Epoch 20/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5374 - mae: 1.5850 - val_loss: 5.0202 - val_mae: 1.6303\n",
            "Epoch 21/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5367 - mae: 1.5846 - val_loss: 5.0161 - val_mae: 1.6298\n",
            "Epoch 22/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5363 - mae: 1.5843 - val_loss: 5.0123 - val_mae: 1.6293\n",
            "Epoch 23/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5360 - mae: 1.5840 - val_loss: 5.0088 - val_mae: 1.6288\n",
            "Epoch 24/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5360 - mae: 1.5837 - val_loss: 5.0057 - val_mae: 1.6283\n",
            "Epoch 25/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5361 - mae: 1.5835 - val_loss: 5.0028 - val_mae: 1.6278\n",
            "Epoch 26/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5363 - mae: 1.5834 - val_loss: 5.0002 - val_mae: 1.6274\n",
            "Epoch 27/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5367 - mae: 1.5832 - val_loss: 4.9978 - val_mae: 1.6270\n",
            "Epoch 28/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5371 - mae: 1.5831 - val_loss: 4.9957 - val_mae: 1.6266\n",
            "Epoch 29/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5377 - mae: 1.5830 - val_loss: 4.9937 - val_mae: 1.6263\n",
            "Epoch 30/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5383 - mae: 1.5829 - val_loss: 4.9919 - val_mae: 1.6260\n",
            "Epoch 31/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5390 - mae: 1.5829 - val_loss: 4.9902 - val_mae: 1.6257\n",
            "Epoch 32/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5397 - mae: 1.5828 - val_loss: 4.9887 - val_mae: 1.6255\n",
            "Epoch 33/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5404 - mae: 1.5828 - val_loss: 4.9873 - val_mae: 1.6252\n",
            "Epoch 34/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5411 - mae: 1.5828 - val_loss: 4.9861 - val_mae: 1.6251\n",
            "Epoch 35/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5419 - mae: 1.5829 - val_loss: 4.9849 - val_mae: 1.6249\n",
            "Epoch 36/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5427 - mae: 1.5829 - val_loss: 4.9838 - val_mae: 1.6247\n",
            "Epoch 37/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5434 - mae: 1.5829 - val_loss: 4.9829 - val_mae: 1.6246\n",
            "Epoch 38/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5442 - mae: 1.5829 - val_loss: 4.9820 - val_mae: 1.6245\n",
            "Epoch 39/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5449 - mae: 1.5830 - val_loss: 4.9812 - val_mae: 1.6244\n",
            "Epoch 40/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5456 - mae: 1.5830 - val_loss: 4.9804 - val_mae: 1.6243\n",
            "Epoch 41/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5463 - mae: 1.5830 - val_loss: 4.9797 - val_mae: 1.6242\n",
            "Epoch 42/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5470 - mae: 1.5831 - val_loss: 4.9791 - val_mae: 1.6241\n",
            "Epoch 43/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5476 - mae: 1.5831 - val_loss: 4.9785 - val_mae: 1.6241\n",
            "Epoch 44/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5482 - mae: 1.5832 - val_loss: 4.9779 - val_mae: 1.6240\n",
            "Epoch 45/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5488 - mae: 1.5832 - val_loss: 4.9774 - val_mae: 1.6240\n",
            "Epoch 46/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5494 - mae: 1.5832 - val_loss: 4.9770 - val_mae: 1.6239\n",
            "Epoch 47/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.5499 - mae: 1.5833 - val_loss: 4.9765 - val_mae: 1.6239\n",
            "Epoch 48/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5504 - mae: 1.5833 - val_loss: 4.9761 - val_mae: 1.6239\n",
            "Epoch 49/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.5509 - mae: 1.5833 - val_loss: 4.9757 - val_mae: 1.6239\n",
            "Epoch 50/50\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5513 - mae: 1.5834 - val_loss: 4.9754 - val_mae: 1.6238\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fa725b0f650>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Callback de Early Stopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    min_delta=0.001,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.MSE,\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "# Entrenamiento\n",
        "model.fit(\n",
        "    X_train_norm,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    validation_split=0.2,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e6040ce5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6040ce5",
        "outputId": "e6f0d1f2-1e78-40e0-8bb0-556160538739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2239 - mae: 1.7518 \n",
            "Test Loss: 5.538976669311523\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de862aa9",
      "metadata": {
        "id": "de862aa9"
      },
      "source": [
        "## Optimizers:\n",
        "\n",
        "- [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD): Gradient descent with momentum\n",
        "```python\n",
        "tf.keras.optimizers.SGD(\n",
        "    learning_rate=0.01, momentum=0.0, nesterov=False, name='SGD', **kwargs\n",
        ")\n",
        "```\n",
        "If momentum is 0:\n",
        "```python\n",
        "w = w - learning_rate * gradient\n",
        "```\n",
        "If we have momentum:\n",
        "\n",
        " ```python\n",
        "velocity = momentum * velocity - learning_rate * g\n",
        "w = w + velocity\n",
        "```\n",
        "\n",
        "\n",
        "- [RMSprop](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop): Root Mean Square Propagation\n",
        "```python\n",
        "tf.keras.optimizers.RMSprop(\n",
        "    learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
        "    name='RMSprop', **kwargs\n",
        ")\n",
        "```\n",
        "- [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam): Adaptive Moment Estimation,  is an update to the RMSProp algorithm\n",
        "```python\n",
        "tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
        "    name='Adam', **kwargs\n",
        ")\n",
        "```\n",
        "\n",
        "```python\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d744232",
      "metadata": {
        "id": "0d744232"
      },
      "source": [
        "## Question 3: Train the same model with different optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17c797bd",
      "metadata": {
        "id": "17c797bd"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "...\n",
        "## model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a81ef1a6",
      "metadata": {
        "id": "a81ef1a6"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=...,\n",
        "    loss=...,\n",
        "    metrics=[...]\n",
        ")\n",
        "model.fit(X_train_norm, y_train, epochs=50, validation_split=0.2, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b36eaf75",
      "metadata": {
        "id": "b36eaf75"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2377a7ff",
      "metadata": {
        "id": "2377a7ff"
      },
      "source": [
        "# Keras Tuner : Introduction to Hyperparameter Optimization\n",
        "\n",
        "The [Keras Tuner](https://www.tensorflow.org/tutorials/keras/keras_tuner) is a library for hyper-parameter tuning.\n",
        "\n",
        "## What is Hyperparameter Tuning?\n",
        "\n",
        "Hyperparameter tuning is the process of finding the optimal set of hyperparameters for a machine learning model to maximize its performance. Unlike model parameters (weights and biases) that are learned during training, hyperparameters are set before the learning process begins and influence how the model learns.\n",
        "\n",
        "Common hyperparameters include:\n",
        "- **Model architecture**: number of layers, units per layer\n",
        "- **Training parameters**: learning rate, batch size, dropout rate\n",
        "- **Regularization**: L1/L2 penalties, early stopping criteria\n",
        "\n",
        "Manual tuning of these parameters can be time-consuming and often leads to suboptimal results. Keras Tuner provides an automated approach to efficiently search the hyperparameter space.\n",
        "\n",
        "## Understanding Different Tuning Strategies\n",
        "\n",
        "Keras Tuner offers four main strategies for hyperparameter optimization:\n",
        "\n",
        "### 1. RandomSearch\n",
        "- **How it works**: Randomly samples from the hyperparameter space\n",
        "- **Pros**: Simple, easily parallelizable, no assumptions about parameter importance\n",
        "- **Cons**: Can be inefficient for large search spaces\n",
        "- **Best for**: Initial exploration or when little is known about the hyperparameter landscape\n",
        "\n",
        "### 2. Hyperband\n",
        "- **How it works**: Allocates resources (epochs) dynamically, quickly discarding poor performers\n",
        "- **Pros**: More efficient than random search, especially for deep networks\n",
        "- **Cons**: More complex to configure correctly\n",
        "- **Best for**: When training is computationally expensive and you want to balance exploration vs. exploitation\n",
        "\n",
        "### 3. BayesianOptimization\n",
        "- **How it works**: Builds a probability model of the objective function and uses it to select hyperparameters\n",
        "- **Pros**: More efficient use of resources, learns from previous evaluations\n",
        "- **Cons**: More complex, computationally intensive for each iteration\n",
        "- **Best for**: When evaluation is expensive and you have a moderate search space\n",
        "\n",
        "### 4. Sklearn\n",
        "- **How it works**: Interface to scikit-learn's hyperparameter search methods\n",
        "- **Pros**: Familiar API for those coming from scikit-learn\n",
        "- **Cons**: Limited to sklearn's hyperparameter tuning capabilities\n",
        "- **Best for**: When integrating with existing sklearn pipelines\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "39e7af43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39e7af43",
        "outputId": "553ebaa8-c9e4-47aa-f145-2f4c38bb3d3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.6.15)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.14.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install -U keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8f47d1f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f47d1f3",
        "outputId": "2a7a89f9-bcd6-4bcb-f860-f9dd4616728c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-15-1654478174.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  import kerastuner as kt\n"
          ]
        }
      ],
      "source": [
        "import kerastuner as kt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7e9b048",
      "metadata": {
        "id": "a7e9b048"
      },
      "source": [
        "Hyperparameters are of two types:\n",
        "1. **Model hyperparameters** like number of units, type of activation or number hidden layers.\n",
        "2. **Algorithm hyperparameters** like the learning rate in adam.\n",
        "\n",
        "The model-building function takes an argument `hp` from which you can sample hyper-parameters.\n",
        "\n",
        "```python\n",
        "def build_model(hp):\n",
        "    ...\n",
        "    return model\n",
        "\n",
        "```\n",
        "\n",
        "- `hp.Int` to sample an integer from a certain range:\n",
        "```python\n",
        "hp.Int('units', min_value=32, max_value=256, step=32, default=64)\n",
        "```\n",
        "- `hp.Float` to sample a float number from a certain range:\n",
        "```python\n",
        "hp.Float('dropout', min_value=0.0, max_value=0.1, default=0.005, step=0.05)\n",
        "```\n",
        "- `hp.Choice` to select values in a list:\n",
        "```python\n",
        "hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "```\n",
        "- [list of hyperparameter methods](https://keras-team.github.io/keras-tuner/documentation/hyperparameters/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ef99c2b2",
      "metadata": {
        "id": "ef99c2b2"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    # Sample different number of layers with hp.Int\n",
        "    for i in range(hp.Int('num_layers', 1, 3)):\n",
        "        # Sample different number of layers with hp.Int\n",
        "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
        "                                            min_value=64,\n",
        "                                            max_value=128,\n",
        "                                            step=32),\n",
        "                               activation='relu'))\n",
        "    # Sample different activation functions with hp.Choice\n",
        "    model.add(layers.Dense(1, activation=hp.Choice('output_activation', ['relu', 'linear'])))\n",
        "\n",
        "    # Sample different activation functions with hp.Choice\n",
        "    model.compile(\n",
        "        loss='mse',\n",
        "        metrics=['mae'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71047eeb",
      "metadata": {
        "id": "71047eeb"
      },
      "source": [
        "The Keras Tuner has four [tuners](https://keras-team.github.io/keras-tuner/documentation/tuners/) available  `RandomSearch`, `Hyperband`, `BayesianOptimization`, and `Sklearn`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f8261f82",
      "metadata": {
        "id": "f8261f82"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "tuner = kt.Hyperband(build_model,\n",
        "                     objective='val_loss',\n",
        "                     max_epochs=15,\n",
        "                     factor=3,\n",
        "                     hyperband_iterations=1,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')\n",
        "'''\n",
        "\n",
        "tuner = kt.RandomSearch(build_model,\n",
        "                     objective='val_loss',\n",
        "                     max_trials=20,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "322e674d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "322e674d",
        "outputId": "6a8b57e2-09f0-454e-cfda-10db79aa8a87"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train_norm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-19-1653591534.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstop_early\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get the optimal hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_hps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_hps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_norm' is not defined"
          ]
        }
      ],
      "source": [
        "tuner.search(X_train_norm, y_train, epochs=20, validation_split=0.15, batch_size=32, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(best_hps.get_config())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1df6dcc9",
      "metadata": {
        "id": "1df6dcc9"
      },
      "outputs": [],
      "source": [
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d31a650",
      "metadata": {
        "id": "9d31a650"
      },
      "outputs": [],
      "source": [
        "print(f\"Best output activation function: {best_hps.get('output_activation')}\")\n",
        "print(f\"Best number of hidden layers: {best_hps.get('num_layers')}\")\n",
        "for i in range(best_hps.get('num_layers')):\n",
        "    print(f\"Number of units of hidden layer {i+1}: {best_hps.get('units_' + str(i))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08bc610d",
      "metadata": {
        "id": "08bc610d"
      },
      "source": [
        "### Hyperparameter Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41f740b0",
      "metadata": {
        "id": "41f740b0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import seaborn as sns\n",
        "\n",
        "def analyze_hyperparameter_importance(tuner, top_n=10):\n",
        "    \"\"\"\n",
        "    Analyze the importance of different hyperparameters using Random Forest.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    tuner : keras_tuner.Tuner\n",
        "        The tuner object after running a hyperparameter search\n",
        "    top_n : int, default=10\n",
        "        Number of top trials to print\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    importance_df : pandas.DataFrame\n",
        "        DataFrame containing the importance of each hyperparameter\n",
        "    \"\"\"\n",
        "    print(\"Extracting hyperparameter data from tuner...\")\n",
        "\n",
        "    # Extract hyperparameters and scores from tuner\n",
        "    hp_results = []\n",
        "\n",
        "    for trial_id, trial in tuner.oracle.trials.items():\n",
        "        if trial.score is not None:  # Only include completed trials\n",
        "            # Get hyperparameters\n",
        "            hp_values = trial.hyperparameters.values\n",
        "            # Add score (lower is better for loss)\n",
        "            hp_values['score'] = trial.score\n",
        "            hp_results.append(hp_values)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    results_df = pd.DataFrame(hp_results)\n",
        "\n",
        "    # Show basic stats\n",
        "    print(f\"Analyzed {len(results_df)} trials\")\n",
        "    print(\"\\nTop {top_n} configurations:\".format(top_n=top_n))\n",
        "    top_configs = results_df.sort_values('score').head(top_n)\n",
        "    for i, (_, config) in enumerate(top_configs.iterrows()):\n",
        "        print(f\"\\nRank {i+1} (Score: {config['score']:.4f}):\")\n",
        "        for param, value in sorted(config.items()):\n",
        "            if param != 'score':\n",
        "                print(f\"  {param}: {value}\")\n",
        "\n",
        "    # Prepare data for Random Forest\n",
        "    X = results_df.drop('score', axis=1)\n",
        "\n",
        "    # Convert non-numeric columns to numeric\n",
        "    for col in X.columns:\n",
        "        if X[col].dtype == 'object':\n",
        "            # Create dummies for categorical variables\n",
        "            dummies = pd.get_dummies(X[col], prefix=col)\n",
        "            X = pd.concat([X.drop(col, axis=1), dummies], axis=1)\n",
        "\n",
        "    y = results_df['score']\n",
        "\n",
        "    # Train Random Forest for feature importance\n",
        "    print(\"\\nTraining Random Forest to analyze hyperparameter importance...\")\n",
        "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    rf.fit(X, y)\n",
        "\n",
        "    # Get feature importance\n",
        "    importance = rf.feature_importances_\n",
        "\n",
        "    # Create DataFrame of features and importance\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Importance': importance\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    # Plot feature importance\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(15))\n",
        "    plt.title('Hyperparameter Importance')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print importance values\n",
        "    print(\"\\nHyperparameter importance ranking:\")\n",
        "    for i, (_, row) in enumerate(importance_df.iterrows()):\n",
        "        if i < 15:  # Print top 15\n",
        "            print(f\"{i+1}. {row['Feature']}: {row['Importance']:.4f}\")\n",
        "\n",
        "    # Analyze top feature's impact with partial dependence plot\n",
        "    top_feature = importance_df.iloc[0]['Feature']\n",
        "    if top_feature in X.columns:  # Ensure it's a numeric feature\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.scatter(X[top_feature], y, alpha=0.6)\n",
        "        plt.title(f'Impact of {top_feature} on Model Performance')\n",
        "        plt.xlabel(top_feature)\n",
        "        plt.ylabel('Score (lower is better)')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    print(\"\\nAnalysis complete. Use these insights to refine your hyperparameter search!\")\n",
        "\n",
        "    return importance_df\n",
        "\n",
        "\n",
        "\n",
        "# After running tuner.search():\n",
        "\n",
        "# 1. Get overall importance\n",
        "importance_df = analyze_hyperparameter_importance(tuner)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6df9ffad",
      "metadata": {
        "id": "6df9ffad"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b439536",
      "metadata": {
        "id": "5b439536"
      },
      "outputs": [],
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(X_train_norm, y_train, epochs=50, validation_split=0.15, callbacks=[stop_early])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57509bd4",
      "metadata": {
        "id": "57509bd4"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cbf5a27",
      "metadata": {
        "id": "6cbf5a27"
      },
      "source": [
        "## Question 4: Try to search with dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27c7b527",
      "metadata": {
        "id": "27c7b527"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    \"\"\"Build a model with tunable architecture and dropout regularization.\"\"\"\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # Tune the number of layers (try 1-4 layers)\n",
        "    for i in range(hp.Int('num_layers', min_value=..., max_value=...)):\n",
        "        # Tune the number of units in each layer\n",
        "        model.add(layers.Dense(\n",
        "            units=hp.Int(f'units_{i}', min_value=..., max_value=..., step=...),\n",
        "            activation=hp.Choice(f'activation_{i}', values=[...])\n",
        "        ))\n",
        "\n",
        "        # Add dropout after the dense layer\n",
        "        # Hint: Experiment with different dropout ranges\n",
        "        model.add(layers.Dropout(\n",
        "            hp...(..., min_value=..., max_value=..., step=...)\n",
        "        ))\n",
        "    '''\n",
        "    # Output layer for regression)\n",
        "    model.add(layers.Dense(1, activation=...))\n",
        "\n",
        "    # Tune the optimizer and learning rate\n",
        "    # Hint: Try different optimizers and log-scale for learning rate\n",
        "    optimizer_choice = hp.Choice('optimizer', values=[...])\n",
        "    learning_rate = hp.Float('learning_rate', min_value=..., max_value=..., sampling=...)\n",
        "\n",
        "    if optimizer_choice == 'adam':\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    elif optimizer_choice == 'rmsprop':\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    else:\n",
        "        optimizer = ...\n",
        "    '''\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss=...,\n",
        "        metrics=[...]\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "659d9de9",
      "metadata": {
        "id": "659d9de9"
      },
      "outputs": [],
      "source": [
        "tuner = kt.Hyperband(build_model,\n",
        "                     objective='val_loss',\n",
        "                     max_epochs=15,\n",
        "                     factor=3,\n",
        "                     hyperband_iterations=1,\n",
        "                     directory='my_dir_2',\n",
        "                     project_name='intro_to_kt')\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=...,\n",
        "    patience=...,\n",
        "    )\n",
        "tuner.search(X_train_norm, y_train, epochs=20, validation_split=0.15,\n",
        "             batch_size=32, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(best_hps.get_config())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eb414e1",
      "metadata": {
        "id": "0eb414e1"
      },
      "outputs": [],
      "source": [
        "print(f\"Best learning rate: {best_hps.get('learning_rate')}\")\n",
        "print(f\"Best output activation function: {best_hps.get('output_activation')}\")\n",
        "print(f\"Best number of hidden layers: {best_hps.get('num_layers')}\")\n",
        "for i in range(best_hps.get('num_layers')):\n",
        "    print(f\"Number of units of hidden layer {i+1}: {best_hps.get('units_' + str(i))}\")\n",
        "    #print(f\"Dropout rate of hidden layer {i+1}: {best_hps.get('dp_' + str(i))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ef4f3df",
      "metadata": {
        "id": "8ef4f3df"
      },
      "outputs": [],
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(X_train_norm, y_train, epochs=50, validation_split=0.15, callbacks=[stop_early])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1f46fac",
      "metadata": {
        "id": "a1f46fac"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results[0]))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}